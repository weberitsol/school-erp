---
title: "Proctored Exams System - Epic & Stories"
version: "1.0.0"
date: 2025-12-27
status: "PLANNING ONLY - NO DEVELOPMENT"
---

# ğŸ¥ EPIC 19: PROCTORED EXAMS SYSTEM
## Real-time Monitoring & Anti-Cheating

---

## ğŸ“‹ OVERVIEW

**Goal:** Enable real-time proctoring of exams to prevent cheating and ensure integrity

**User Outcome:** Teachers can monitor students live; students' exams are recorded with integrity verification

**Scope:** Both web and mobile platforms
- **Web**: Teachers monitor test-taking in real-time
- **Mobile**: Students take proctored tests with camera/microphone active

**Complexity**: HIGH (involves audio/video, real-time streaming, AI detection)

---

## ğŸ¯ PROCTORING ARCHITECTURE

### **Proctoring Flow**

```
STUDENT SIDE:
â”œâ”€ Test starts
â”œâ”€ Permission requests: Camera, Microphone
â”œâ”€ Face detection: Verifies student identity
â”œâ”€ Video capture: Starts recording
â”œâ”€ Screen monitoring: Tracks device activity
â”œâ”€ Continuous checks: Face presence, eye movement, etc.
â””â”€ Test ends â†’ Video uploaded

TEACHER SIDE:
â”œâ”€ Live monitoring dashboard
â”œâ”€ View student video feeds (grid view)
â”œâ”€ Watch active/idle students
â”œâ”€ Receive alerts (suspicious activity)
â”œâ”€ Record all monitoring for review
â””â”€ Generate proctoring report

SERVER SIDE:
â”œâ”€ Video streaming (WebRTC/HLS)
â”œâ”€ Face detection (AI model)
â”œâ”€ Suspicious activity detection
â”œâ”€ Video storage (S3/R2)
â”œâ”€ Activity logging
â””â”€ Alert triggering
```

### **Monitoring Points**

```
VIDEO/AUDIO:
â”œâ”€ Face visibility (must stay on camera)
â”œâ”€ Eye contact (looking at screen, not away)
â”œâ”€ Head position (normal, not tilted)
â”œâ”€ Multiple faces (prevent proxying)
â”œâ”€ Background activity (others entering room)

DEVICE:
â”œâ”€ App in foreground (not switching apps)
â”œâ”€ Only test window visible
â”œâ”€ No screen recording/casting (except proctor)
â”œâ”€ No external displays connected
â”œâ”€ No other apps running

BEHAVIORAL:
â”œâ”€ Unusual answer patterns
â”œâ”€ Too fast completion time
â”œâ”€ Long pauses (suspicious thinking)
â”œâ”€ Multiple tabs open (impossible)
â”œâ”€ Copy-paste attempts

NETWORK:
â”œâ”€ VPN usage (flag suspicious)
â”œâ”€ IP changes during exam
â”œâ”€ Packet inspection (detect remote control)
```

---

## ğŸ“ STORIES

### **EPIC 19: PROCTORED EXAMS SYSTEM**

#### **Story 19.1: Camera and Microphone Activation**
**As a** student
**I want** to enable camera and microphone for proctored test
**So that** the test can be monitored and recorded

**Acceptance Criteria:**
- Given test marked as proctored, When started, Then permission requests shown
- Given camera permission, When granted, Then camera feed displays in corner
- Given microphone permission, When granted, Then audio input confirmed
- Given permission denied, When user denies, Then clear explanation shown
- Given permissions denied, When both rejected, Then test cannot start with warning
- Given camera feed, When displayed, Then 15 FPS minimum quality
- Given microphone, When active, Then audio levels shown as indicator

**Technical Notes:**
- Permissions: CAMERA, RECORD_AUDIO (Android)
- Library: CameraX for camera, MediaRecorder for audio
- Preview: Small corner window (not obstructing test)
- Fallback: If no camera, can use web cam requirement message
- Persistent: Keep recording until test submitted
- Quality: H.264 video codec, AAC audio

---

#### **Story 19.2: Face Detection and Verification**
**As a** security system
**I want** to detect and verify student's face throughout test
**So that** same student remains present during entire exam

**Acceptance Criteria:**
- Given test start, When face detected, Then verified against enrolled face
- Given enrollment photo, When compared, Then similarity score calculated (>90% match required)
- Given multiple faces, When detected, Then immediately flagged for review
- Given no face detected, When absent > 30 seconds, Then warning shown to student
- Given repeated warnings, When ignored, Then test paused and alert sent
- Given face away, When looking away > 15 seconds, Then logged as suspicious
- Given valid detection, When face present and focused, Then continue normally

**Technical Notes:**
- Face detection: ML Kit Face Detection API or similar
- Face enrollment: Store face embedding (not full image for privacy)
- Similarity: Face recognition model (e.g., FaceNet, ArcFace)
- Matching threshold: > 90% for acceptance
- Spoofing prevention: Liveness check (blink detection, smile)
- Processing: Local on device (not sent to server)
- Logging: Track face presence at 5-second intervals

---

#### **Story 19.3: Video Recording and Storage**
**As a** system
**I want** to record video of test-taking session
**So that** evidence is available for review if needed

**Acceptance Criteria:**
- Given test starts, When proctored, Then video recording begins
- Given recording, When ongoing, Then stored locally first (backup)
- Given test ends, When submitted, Then video uploaded to server
- Given upload failure, When network error, Then retry automatically
- Given upload success, When completed, Then stored in secure location
- Given video duration, When test 3 hours, Then stored without compression loss
- Given privacy, When stored, Then encrypted and access-controlled
- Given retention, When result published, Then video kept for 90 days minimum

**Technical Notes:**
- Recording: MediaRecorder or FFmpeg
- Format: MP4 with H.264 video, AAC audio
- Bitrate: 2-3 Mbps (balance quality and size)
- Storage local: Device cache while test in progress
- Upload: Split into 10-minute chunks, resume on failure
- Server storage: Cloudflare R2 encrypted
- Access: Only teacher/admin of that school, encrypted URLs
- Retention: Delete after 90 days (configurable per school policy)
- Size estimate: 3-hour test = 2.5-3.5 GB

---

#### **Story 19.4: Eye Gaze and Attention Monitoring**
**As a** security system
**I want** to monitor where student is looking
**So that** cheating via external materials is detected

**Acceptance Criteria:**
- Given eye position, When detected, Then tracked relative to screen
- Given gaze focus, When on test area, Then recorded as normal
- Given gaze away, When looking away > 10 seconds, Then flagged (soft warning)
- Given repeated gaze away, When > 5 times, Then escalated alert
- Given eye closure, When > 5 seconds, Then flagged as suspicious
- Given gaze pattern, When unusual, Then analyzed for cheating signals
- Given alert threshold, When exceeded, Then teacher notified

**Technical Notes:**
- Eye tracking: ML Kit Eye Detector or GazeML
- Accuracy: Works best with good lighting
- Tracking frequency: Every 500ms
- Thresholds:
  - Gaze away: 10 seconds = soft warning to student
  - Closed eyes: 5 seconds = flag for review
  - Head tilted: > 30 degrees = suspicious
- Fallback: If eye tracking fails, use head position instead
- Privacy: Local processing, no eye data sent to server
- Limitation: May fail with glasses or poor lighting

---

#### **Story 19.5: Head Position and Posture Detection**
**As a** security system
**I want** to monitor student's head position
**So that** unusual movements (passing answer sheet) are detected

**Acceptance Criteria:**
- Given head position, When monitored, Then normal upright position expected
- Given head tilt, When > 30 degrees, Then flagged as suspicious
- Given head down, When for > 5 seconds, Then warning shown
- Given head turned away, When > 20 degrees off screen, Then suspicious
- Given posture changes, When rapid, Then logged for pattern analysis
- Given repetitive head movement, When detected, Then potential signal flagged

**Technical Notes:**
- Detection: Pose estimation ML Kit or MediaPipe
- Keypoints: Detect face landmarks and head orientation
- Thresholds:
  - Tilt angle: > 30 degrees = suspicious
  - Turn angle: > 20 degrees from camera = red flag
  - Down position: > 5 seconds = flag
- Frequency: Check every 500ms
- Pattern analysis: Multiple rapid turns = potential signal communication
- Logging: Store all movements for forensic review

---

#### **Story 19.6: Background and Environment Monitoring**
**As a** security system
**I want** to monitor test environment for suspicious activity
**So that** external assistance is detected

**Acceptance Criteria:**
- Given background, When visible, Then scanned for other people
- Given other face, When detected in background, Then flagged immediately
- Given object appearance, When suspicious item detected, Then flagged
- Given environment change, When lights/background changes, Then logged
- Given room scan, When before test start, Then optional room verification
- Given phone/device visibility, When detected, Then flagged suspicious

**Technical Notes:**
- People detection: Object detection (YOLO or SSD)
- Suspicious objects: Books, papers, phones, laptops in background
- Initial scan: Room scan via 360Â° camera sweep before test
- Continuous monitoring: Detect any new people entering frame
- Alert threshold: Any person in background = immediate alert
- Exceptions: Family members (configurable per school)
- False positives: Adjust sensitivity for shared spaces (libraries, homes)

---

#### **Story 19.7: Real-time Proctoring Dashboard (Teacher)**
**As a** teacher
**I want** to monitor students taking the test in real-time
**So that** I can observe suspicious behavior and intervene

**Acceptance Criteria:**
- Given test in progress, When opened by teacher, Then student video feeds shown
- Given video grid, When displayed, Then all test-takers visible (10-20 per page)
- Given student click, When selected, Then full-screen view with stats
- Given suspicious alert, When triggered, Then highlighted/flagged in red
- Given alert history, When viewed, Then timeline of all alerts shown
- Given student interaction, When clicked, Then can send text/audio warning
- Given recording, When active, Then status indicator shown to student
- Given exam ended, When all students finish, Then recording stops

**Technical Notes:**
- Dashboard: Real-time video grid view
- Video streaming: WebRTC for low-latency or HLS for fallback
- Grid view: 4x5 (20 students max per view, pagination available)
- Full-screen view: Selected student with:
  - Large video
  - Alert timeline
  - Answer stats
  - Face detection status
  - Eye gaze visualization
  - Posture indicators
- Controls:
  - Send warning message (text appears on student screen)
  - Send audio announcement
  - Flag for review
  - End session (forcefully stop student)
- Connection quality: Show video quality indicator
- Bandwidth: Optimize for 2-4 Mbps per student feed

---

#### **Story 19.8: Student Alerts and Warnings**
**As a** student
**I want** to see alerts if my behavior is suspicious
**So that** I can correct and continue test

**Acceptance Criteria:**
- Given suspicious activity, When detected, Then warning message shown
- Given warning message, When displayed, Then clear and actionable (e.g., "Face not visible - look at camera")
- Given soft warning, When shown, Then doesn't pause test
- Given repeated warnings, When > 3 times, Then test paused with message
- Given hard pause, When teacher manually pauses, Then test stops and message shown
- Given resume option, When teacher allows, Then student can continue
- Given audio announcement, When sent by teacher, Then plays clearly with notification

**Technical Notes:**
- Warning levels:
  - Level 1 (Info): Onscreen message, no pause
  - Level 2 (Caution): Visible warning + audio beep
  - Level 3 (Critical): Test paused, requires teacher to resume
- Messages: Pre-written templates
  - "Face not visible - look at camera"
  - "Multiple faces detected - ensure you're alone"
  - "You looked away - focus on test"
  - "Suspicious activity detected - exam under review"
- Tone: Non-accusatory, helpful, supportive
- Display: 10-second timeout on warnings

---

#### **Story 19.9: Suspicious Activity Detection**
**As a** security system
**I want** to detect and flag unusual patterns
**So that** potential cheating is identified

**Acceptance Criteria:**
- Given answer pattern, When compared to class average, Then outliers detected
- Given timing, When too fast for complexity, Then flagged
- Given gaze pattern, When unusual (looking away frequently), Then flagged
- Given network anomaly, When detected (VPN, proxy), Then flagged
- Given device anomaly, When detected (rooted, emulator), Then flagged
- Given combination factors, When multiple flags, Then escalated to critical
- Given flagged session, When reviewed, Then teacher can see all flags with evidence

**Technical Notes:**
- Detection triggers:
  ```
  Answer too fast:
  â”œâ”€ Average time per question < 10 seconds = flag
  â”œâ”€ Baseline: Compare to student's previous tests
  â””â”€ All correct + fastest = double flag

  Gaze patterns:
  â”œâ”€ Looking away > 50% of time = flag
  â”œâ”€ Sudden gaze changes = flag
  â””â”€ Focused on one corner = flag (possible cheat sheet)

  Device:
  â”œâ”€ Root detected = block
  â”œâ”€ Emulator detected = flag
  â”œâ”€ VPN = flag
  â””â”€ USB debugging = flag

  Network:
  â”œâ”€ IP change mid-test = flag
  â”œâ”€ Packet loss > 10% = suspicious
  â””â”€ Connection unstable = log for review
  ```
- Scoring: 0-100 confidence score per flag
- Aggregation: Total risk score determines action
- Escalation: Risk > 80 = auto-flag for manual review

---

#### **Story 19.10: Proctoring Report and Review**
**As a** admin
**I want** to review proctoring records and generate reports
**So that** I can identify cheating and take action

**Acceptance Criteria:**
- Given flagged exam, When reviewed, Then video and alert timeline visible
- Given video playback, When played, Then shows timeline with flags marked
- Given specific flag, When clicked, Then video seeks to that moment
- Given timestamp, When shown, Then correlates with answer submission time
- Given comparison, When viewed, Then can compare with class/other students
- Given verdict, When made, Then can mark as CLEAN/SUSPICIOUS/INVALID
- Given report, When generated, Then summary with statistics exported
- Given appeal, When student contests, Then evidence easily reviewable

**Technical Notes:**
- Review interface:
  - Left: Video player with timeline and flags
  - Right: Alert list with timestamps
  - Center: Test answers and response times
  - Synchronized playback of all three
- Comparison views:
  - Similar answers from other students
  - Answer patterns over time
  - Gaze patterns vs answer correctness
- Flagging system:
  - CLEAN: No suspicious activity
  - MINOR: 1-2 minor flags, likely false positives
  - SUSPICIOUS: 3+ flags or 1 major flag
  - CONFIRMED: Definitive evidence of cheating
- Report template:
  - Student name, exam, date
  - Alert summary (count by type)
  - Key moments (with video links)
  - Risk assessment
  - Recommendation

---

#### **Story 19.11: Liveness Detection (Anti-Spoofing)**
**As a** security system
**I want** to ensure the face is real (not photo/video)
**So that** student identity is authentic

**Acceptance Criteria:**
- Given face detected, When liveness checked, Then must pass anti-spoofing
- Given photo/screenshot, When used as fake, Then rejected
- Given video replay, When attempted, Then detected and rejected
- Given blink requirement, When needed, Then student must blink
- Given expression, When varied, Then must show natural expressions
- Given depth detection, When available, Then 3D face required (not 2D image)

**Technical Notes:**
- Liveness checks:
  - Blink detection: Require genuine eye closure
  - Head movement: Require head rotation
  - Smile: Require genuine smile
  - Eye tracking: Eyes follow object motion
- Detection method:
  - Texture analysis: Real face has texture, photo is flat
  - Motion analysis: Real movement vs static/replayed
  - Depth sensing: If device has depth camera, use it
  - Frequency analysis: Detect if video pattern (24/30 fps)
- False positive rate: Keep < 5% (genuine users accepted)
- False negative rate: Keep < 1% (block fake attempts)
- Fallback: If liveness fails, require manual review by proctor

---

#### **Story 19.12: Test Environment Verification**
**As a** proctor
**I want** student to verify their test environment
**So that** physical setup is appropriate

**Acceptance Criteria:**
- Given room scan, When requested before test, Then student rotates camera 360Â°
- Given video capture, When recorded, Then saved with exam for review
- Given prohibited items, When visible, Then alert shown (e.g., "Books detected")
- Given approval, When satisfied, Then teacher can approve or require cleanup
- Given room change, When environment changes mid-exam, Then alert triggered
- Given final scan, When test ending, Then room scan repeated to verify

**Technical Notes:**
- Room scan process:
  1. Student starts test
  2. Shown instructions: "Scan your entire room, show desk, no books/devices visible"
  3. Camera records 20-30 seconds of room panorama
  4. AI scans for suspicious items
  5. Proctor reviews and approves/rejects
- Prohibited items detection:
  - Books: Detect if visible
  - Papers: Multiple sheets flagged
  - Phones: Obvious red flag
  - Laptops: Monitor/keyboard visible = flag
  - Multiple displays: Only one allowed
- Approval workflow:
  - Auto-approve if no items found
  - Proctor reviews if items detected
  - Can ask student to clear workspace and re-scan

---

#### **Story 19.13: WebRTC Streaming for Live Proctoring**
**As a** backend
**I want** low-latency video streaming to proctors
**So that** real-time monitoring is possible

**Acceptance Criteria:**
- Given student camera, When streaming, Then latency < 500ms
- Given teacher dashboard, When opened, Then receives live stream
- Given connection stable, When maintained, Then continuous feed
- Given connection unstable, When lost, Then attempts auto-reconnect
- Given multiple students, When viewed, Then manages multiple streams
- Given bandwidth limited, When detected, Then quality adapts

**Technical Notes:**
- Technology: WebRTC for peer-to-peer low latency
- Server role: Signaling server for initial connection
- Streaming protocol: SRTP (Secure RTP)
- Codec: VP8 or H.264
- Bitrate: 1-2 Mbps per stream (adaptive)
- Video resolution: 480p or 720p depending on bandwidth
- Audio: AAC 64 kbps
- Latency target: < 500ms (real-time acceptable)
- Fallback: HLS for web, lower quality but more compatible
- Server: TURN server for NAT traversal (if P2P fails)

---

#### **Story 19.14: Consent and Legal Compliance**
**As a** system
**I want** student to consent to proctoring
**So that** legal and privacy requirements met

**Acceptance Criteria:**
- Given proctored test, When about to start, Then consent form shown
- Given form content, When displayed, Then clearly explains what is recorded
- Given agreement required, When consent needed, Then cannot proceed without
- Given consent scope, When provided, Then specifies: video, audio, screen
- Given right to decline, When applicable, Then option to take non-proctored version
- Given saved consent, When recorded, Then timestamp and signature stored
- Given GDPR, When applicable, Then right to delete video after grade published
- Given data retention, When specified, Then shown to student upfront

**Technical Notes:**
- Consent form template:
  ```
  EXAM PROCTORING CONSENT

  This exam is proctored. By clicking "I Agree", you consent to:

  âœ“ Video recording of your face and upper body
  âœ“ Audio recording of sound in your environment
  âœ“ Screen/device monitoring for suspicious activity
  âœ“ Real-time monitoring by proctors
  âœ“ Recording storage for 90 days for review if needed

  Your data will be:
  - Encrypted in transit and at rest
  - Accessible only to teachers/admins of your school
  - Deleted 90 days after exam completion

  You have the right to:
  - Request video deletion after result is final
  - Know if suspicious activity was detected
  - Appeal any cheating findings

  [ I Agree ]  [ Decline & Take Non-Proctored Test ]
  ```
- Storage: Consent record with timestamp and student signature
- GDPR: Keep audio/video only if necessary, delete on request
- Jurisdiction: Adapt to local laws (COPPA for US children, etc.)

---

#### **Story 19.15: Proctoring Analytics and Statistics**
**As a** admin
**I want** analytics on proctoring across school
**So that** I can understand cheating patterns

**Acceptance Criteria:**
- Given all exams, When analyzed, Then statistics calculated
- Given flags per exam, When summed, Then percentage of students with flags shown
- Given common flags, When identified, Then top cheating methods listed
- Given false positive rate, When calculated, Then helps calibrate thresholds
- Given comparative stats, When compared, When help identify problematic exams
- Given trend, When tracked over time, Then shows if cheating increasing/decreasing
- Given export, When requested, Then statistics available as report

**Technical Notes:**
- Metrics:
  ```
  Per exam:
  â”œâ”€ Total test-takers
  â”œâ”€ Students flagged (count, %)
  â”œâ”€ Common flags (face away, suspicious speed, etc.)
  â”œâ”€ Average flag count per student
  â””â”€ Confirmed cheating rate (% of flagged with evidence)

  Per student:
  â”œâ”€ Exams taken with proctoring
  â”œâ”€ Times flagged
  â”œâ”€ Conviction rate (% of flags that were actual cheating)
  â””â”€ Pattern (improving vs consistent)

  By flag type:
  â”œâ”€ Face not visible: count, %
  â”œâ”€ Gaze away: count, %
  â”œâ”€ Multiple people: count, %
  â”œâ”€ Suspicious speed: count, %
  â””â”€ Pattern unusual: count, %
  ```
- Dashboard: Charts showing trends and breakdowns
- Comparison: Exam to exam, class to class
- Export: CSV/PDF report with all statistics

---

## ğŸ¯ PROCTORING MODES

### **Mode 1: Live Proctoring (Real-time)**
```
Teacher watches student LIVE during test
â”œâ”€ Best for: High-stakes exams, competitive exams
â”œâ”€ Cost: Higher (need proctors per exam)
â”œâ”€ Latency: < 500ms (real-time)
â”œâ”€ Intervention: Can warn/pause student immediately
â”œâ”€ Evidence: Video stream recorded
â””â”€ Recommendation: National exams, university entrance
```

### **Mode 2: Recorded Proctoring (Asynchronous)**
```
Student test recorded, teacher reviews if flagged
â”œâ”€ Best for: School exams, unit tests
â”œâ”€ Cost: Lower (batch review possible)
â”œâ”€ Review time: Later, not real-time
â”œâ”€ Intervention: Via review, not during test
â”œâ”€ Evidence: Full video recording available
â””â”€ Recommendation: Regular school exams
```

### **Mode 3: AI Proctoring (Automated)**
```
AI detects suspicious activity, alerts teacher
â”œâ”€ Best for: Online courses, assignments
â”œâ”€ Cost: Lowest (fully automated)
â”œâ”€ Detection: Real-time alerts via ML
â”œâ”€ Intervention: Teacher reviews and decides
â”œâ”€ Evidence: Automated detection + video
â””â”€ Recommendation: Practice tests, formative assessments
```

---

## ğŸ”’ PRIVACY SAFEGUARDS

```
DATA COLLECTION:
â”œâ”€ Consent: Explicit consent before recording
â”œâ”€ Scope: Limited to what's necessary for proctoring
â”œâ”€ Transparency: Clear about what's recorded and used
â””â”€ Purpose: Only for exam integrity, not other uses

DATA STORAGE:
â”œâ”€ Encryption: AES-256 at rest, TLS in transit
â”œâ”€ Access: Only authorized teachers/admins
â”œâ”€ Segregation: Stored separately from exam answers
â”œâ”€ Location: Secure cloud (Cloudflare R2)
â””â”€ Retention: Delete after 90 days default

DATA DELETION:
â”œâ”€ Automatic: Delete 90 days post-exam
â”œâ”€ On-request: Student can request deletion
â”œâ”€ Post-result: Can delete when result is final
â”œâ”€ GDPR-compliant: Right to be forgotten
â””â”€ Audit trail: Log of what was deleted

FAIRNESS:
â”œâ”€ False positives: Don't base verdict solely on automated flags
â”œâ”€ Appeal process: Students can appeal cheating findings
â”œâ”€ Context: Flags show suspicious activity, not proof
â”œâ”€ Manual review: Human reviews video for context
â””â”€ Leniency: First-time minor violations may not be punished
```

---

## ğŸ“Š IMPLEMENTATION CONSIDERATIONS

### **Bandwidth Requirements**
```
Per student:
â”œâ”€ Video stream: 2-4 Mbps (during test)
â”œâ”€ Audio stream: 64 kbps
â”œâ”€ Metadata/logs: 1 kbps
â”œâ”€ Total: ~2.1-4.1 Mbps per student

For 100 concurrent students:
â”œâ”€ Total: 210-410 Mbps (incoming to server)
â”œâ”€ Storage (1 hour): 900 GB - 1.8 TB
â”œâ”€ 3-hour exam: 2.7-5.4 TB per exam
â””â”€ Monthly (10 exams): 27-54 TB

Cost implications:
â”œâ”€ Bandwidth: AWS/Azure regional: ~$0.02/GB = $540-1080 per exam
â”œâ”€ Storage: R2: ~$0.015/GB month = $810-1620 per month
â””â”€ Estimated monthly: $2000-3500 for proctoring infrastructure
```

### **Computational Requirements**
```
ML Models (per student):
â”œâ”€ Face detection: 5% CPU
â”œâ”€ Eye tracking: 8% CPU
â”œâ”€ Pose estimation: 5% CPU
â”œâ”€ Object detection: 10% CPU
â””â”€ Total per device: ~28% CPU (manageable)

Server-side processing:
â”œâ”€ Video encoding/transcoding: GPU needed
â”œâ”€ Face recognition: GPU needed
â”œâ”€ Alert logic: CPU
â””â”€ Recommendation: GPU instance (AWS g4dn or similar)
```

### **Device Compatibility**
```
REQUIREMENTS:
â”œâ”€ Camera: Front-facing, minimum 2MP
â”œâ”€ Microphone: Working audio input
â”œâ”€ Processor: Qualcomm 660 or better
â”œâ”€ RAM: 4GB minimum (6GB recommended)
â”œâ”€ Storage: 1GB free space for video buffer
â”œâ”€ Network: 5+ Mbps upload (for streaming)
â”œâ”€ Screen: 5.5"+ recommended for test readability

TESTING NEEDED:
â”œâ”€ Low-end devices: Snapdragon 665, 4GB RAM
â”œâ”€ Poor lighting: What is minimum lighting needed?
â”œâ”€ Weak network: How to degrade gracefully?
â”œâ”€ Glasses/sunglasses: Fails face detection?
â”œâ”€ Disabilities: Accessible for all users?
```

---

## ğŸš€ ROLLOUT STRATEGY

### **Phase 1: Pilot (Week 1-2)**
```
Scope: Limited to specific class/exam
â”œâ”€ Teachers: 2-3 volunteering teachers
â”œâ”€ Students: 20-30 students
â”œâ”€ Mode: Recorded proctoring (less pressure)
â”œâ”€ Feedback: Gather issues and improve
â””â”€ Success metric: 95% tests completed without technical issues
```

### **Phase 2: Soft Launch (Week 3-4)**
```
Scope: Expand to school level
â”œâ”€ Teachers: All interested teachers
â”œâ”€ Students: All class 10+ (can opt-in to live proctoring)
â”œâ”€ Mode: Recorded + AI alerts
â”œâ”€ Support: Technical support team on call
â””â”€ Success metric: 99% completion, <5% technical issues
```

### **Phase 3: Full Rollout (Week 5+)**
```
Scope: All exams with optional proctoring
â”œâ”€ Teachers: All
â”œâ”€ Students: All
â”œâ”€ Mode: Choice of: Live, Recorded, or Non-proctored
â”œâ”€ Policies: Clear school policies on usage
â””â”€ Success metric: Adoption rate >80%, cheating incidents down
```

---

## âš ï¸ RISKS & MITIGATIONS

| Risk | Severity | Mitigation |
|------|----------|-----------|
| **Privacy concerns** | HIGH | Clear consent, GDPR compliance, data deletion |
| **Technical failures** (camera crash) | HIGH | Fallback non-proctored option, retry mechanisms |
| **False positive cheating accusations** | HIGH | Manual review, appeal process, evidence required |
| **Bandwidth limitations** | MEDIUM | Adaptive quality, prioritize video over audio |
| **Student anxiety** (watched during test) | MEDIUM | Education, clear guidelines, reassurance |
| **Device incompatibility** | MEDIUM | Minimum device specs, fallback options |
| **Racial bias in face detection** | MEDIUM | Diverse training data, human review for edge cases |
| **Performance on low-end devices** | MEDIUM | Optimize models, off-device processing where possible |

---

## ğŸ“‹ STORIES SUMMARY

```
Total Proctoring Stories: 15

Core Features (6):
â”œâ”€ 19.1: Camera & Microphone activation
â”œâ”€ 19.2: Face detection & verification
â”œâ”€ 19.3: Video recording & storage
â”œâ”€ 19.4: Eye gaze monitoring
â”œâ”€ 19.5: Head position monitoring
â””â”€ 19.6: Background monitoring

Teacher & Admin (4):
â”œâ”€ 19.7: Proctoring dashboard (teacher)
â”œâ”€ 19.10: Proctoring report & review (admin)
â”œâ”€ 19.12: Test environment verification
â””â”€ 19.15: Analytics & statistics

Student & Security (3):
â”œâ”€ 19.8: Student alerts & warnings
â”œâ”€ 19.9: Suspicious activity detection
â””â”€ 19.11: Liveness detection

Infrastructure (2):
â”œâ”€ 19.13: WebRTC streaming
â””â”€ 19.14: Consent & legal compliance
```

---

## ğŸ”„ INTEGRATION WITH EXISTING SYSTEMS

### **Integration with Epic 13 (Offline Test-Taking)**

```
CHALLENGE:
â”œâ”€ Mobile app is OFFLINE
â”œâ”€ Proctoring requires REAL-TIME video
â””â”€ Conflict: Can't proctor offline tests

SOLUTION - DUAL MODE:
â”œâ”€ Offline proctoring: NOT supported
â”‚  â””â”€ Mobile offline = non-proctored tests
â”œâ”€ Online proctoring: Fully supported
â”‚  â””â”€ Web platform = proctored tests
â””â”€ Policy:
   â”œâ”€ High-stakes exams: Proctored (online only)
   â”œâ”€ Regular exams: Optional proctoring (online)
   â””â”€ Practice tests: No proctoring (online/offline)

IMPLEMENTATION:
â”œâ”€ Test setup: Choose proctoring yes/no
â”œâ”€ Mobile app: Rejects proctored tests in offline mode
â”œâ”€ Web fallback: Web-based test for proctored exams
â””â”€ Sync: Non-proctored mobile responses sync normally
```

### **Integration with Epic 7 (Exam Management)**

```
TEST SETUP:
â”œâ”€ Exam creation: New field "Proctoring" (None/Recorded/Live)
â”œâ”€ Proctoring config:
â”‚  â”œâ”€ Live proctor assignments
â”‚  â”œâ”€ Alert thresholds
â”‚  â””â”€ Environment requirements
â””â”€ Student instructions: "This exam is proctored"

TEST EXECUTION:
â”œâ”€ Test start: Show consent if proctored
â”œâ”€ During test: Activate monitoring systems
â”œâ”€ Real-time: Send alerts to teacher if live
â””â”€ Submission: Upload video + responses

RESULT REVIEW:
â”œâ”€ Automated: AI flags suspicious activity
â”œâ”€ Manual: Teacher reviews flagged exams
â”œâ”€ Decision: Mark clean or invalid
â””â”€ Appeal: Student can request review
```

---

## ğŸ“š TECHNICAL STACK FOR PROCTORING

```
CLIENT (Mobile):
â”œâ”€ Camera: CameraX (AndroidX)
â”œâ”€ Face detection: ML Kit Face Detection
â”œâ”€ Pose estimation: MediaPipe
â”œâ”€ Video encoding: MediaRecorder
â”œâ”€ WebRTC: Peerjs or Android native
â””â”€ Liveness: Local liveness detection SDK

SERVER:
â”œâ”€ Video streaming: Kurento or Janus (WebRTC server)
â”œâ”€ Face recognition: FaceNet or ArcFace (TensorFlow)
â”œâ”€ Object detection: YOLO or SSD
â”œâ”€ Video storage: Cloudflare R2 + transcoding
â”œâ”€ Alert system: Real-time notifications
â””â”€ Dashboard: WebRTC client + Socket.io

Infrastructure:
â”œâ”€ GPU instances: For ML model inference
â”œâ”€ CDN: For video delivery
â”œâ”€ Load balancer: Distribute streaming load
â”œâ”€ Message queue: For async processing
â””â”€ Monitoring: Video quality, latency, errors
```

---

## âœ… ACCEPTANCE CRITERIA FOR MVP

```
CORE PROCTORING MVP:
âœ“ Students can enable camera/mic with consent
âœ“ Face detection verifies student identity
âœ“ Video records during test
âœ“ Teacher can view live feed (if live mode)
âœ“ Suspicious activities are flagged
âœ“ Video is stored securely
âœ“ Admin can review flagged exams
âœ“ No false accusations (evidence-based decisions)

QUALITY TARGETS:
âœ“ Video streaming latency < 500ms
âœ“ False positive rate < 5%
âœ“ False negative rate < 1%
âœ“ Detection accuracy > 90%
âœ“ 99.9% test completion despite monitoring

COMPLIANCE:
âœ“ GDPR compliant (consent, deletion)
âœ“ COPPA compliant (children's privacy)
âœ“ Video encrypted in transit and storage
âœ“ Access controlled (only authorized viewers)
âœ“ Audit trail of all access
```

---

## ğŸ“ NEXT STEPS

1. **Review with school principals** - Is this acceptable at your school?
2. **Design consent forms** - Legal team approval
3. **Set school policies** - When/how to use proctoring
4. **Pilot testing** - Test with small group first
5. **Feedback iteration** - Improve based on experience
6. **Full deployment** - Roll out across school

---

**Status**: PLANNING ONLY - NO DEVELOPMENT
**Last Updated**: 2025-12-27
**Ready for**: Team discussion and school policy review
